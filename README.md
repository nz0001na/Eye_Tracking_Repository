# Eye_Tracking_Repository
This repository collects methods and databases in the field of eye tracking.

Keep updating!!!

[[report]](https://github.com/nz0001na/Eye_Tracking_Repository/blob/main/literature_review.pdf)

# Survey
* 2022	Eye gaze estimation: A survey on deep learning-based approaches		[[paper]](https://www.sciencedirect.com/science/article/abs/pii/S0957417422003347)
* 2021	Appearance-based Gaze Estimation With Deep Learning: A Review and Benchmark	website	paper
  [[project]](http://phi-ai.buaa.edu.cn/Gazehub/), [[paper]](http://phi-ai.buaa.edu.cn/publications/index.htm)

# Databases
## Image-based:
* 2015	MPIIGaze		[[paper]](https://paperswithcode.com/paper/appearance-based-gaze-estimation-in-the-wild),	[[project]](https://paperswithcode.com/dataset/mpiigaze)
* 2016	GazeCapture		[[paper]](https://paperswithcode.com/paper/eye-tracking-for-everyone),	[[project]](https://paperswithcode.com/dataset/gazecapture)
* 2017	MPIIFaceGaze	[[project]](https://www.perceptualui.org/research/datasets/MPIIFaceGaze/)	
* 2017	InvisibleEye  [[paper]](https://dl.acm.org/doi/10.1145/3130971)		
* 2018	RT-GENE		[[paper]](https://paperswithcode.com/paper/rt-gene-real-time-eye-gaze-estimation-in),	[[project]](https://paperswithcode.com/dataset/rt-gene)
* 2019	Gaze360		[[paper]](https://paperswithcode.com/paper/gaze360-physically-unconstrained-gaze),	[[project]](https://paperswithcode.com/dataset/gaze360)
* 2020	ETH-XGaze		[[paper]](https://paperswithcode.com/paper/eth-xgaze-a-large-scale-dataset-for-gaze),	[[project]](https://paperswithcode.com/dataset/eth-xgaze)
## Video-based:
* 2014	EYEDIAP		[[paper]](https://dl.acm.org/doi/10.1145/2578153.2578190),	[[project]](https://paperswithcode.com/dataset/eyediap)
* 2017	TabletGaze [[paper]](https://arxiv.org/abs/1508.01244), [[project]](https://sh.rice.edu/cognitive-engagement/tabletgaze/)
* 2020	EVE		[[paper]](https://paperswithcode.com/paper/towards-end-to-end-video-based-eye-tracking),	[[project]](https://paperswithcode.com/dataset/eve)



# Algorithms
## Image-based methods
* 2021		Generalizing Gaze Estimation with Outlier-guided Collaborative Adaptation	[[paper]](https://openaccess.thecvf.com/content/ICCV2021/html/Liu_Generalizing_Gaze_Estimation_With_Outlier-Guided_Collaborative_Adaptation_ICCV_2021_paper.html),	[[code]](https://github.com/DreamtaleCore/PnP-GA),	[[project]](https://liuyunfei.net/publication/iccv2021_pnp-ga/)
* 2021		Gaze Estimation using Transformer	[[paper]](https://arxiv.org/abs/2105.14424),	[[code]](https://github.com/yihuacheng/GazeTR)	
* 2021		FLAME: Facial Landmark Heatmap Activated Multimodal Gaze Estimation	[[paper]](https://arxiv.org/abs/2110.04828),	[[code]](https://github.com/neelabhsinha/flame)	
* 2022		Learning-by-Novel-View-Synthesis for Full-Face Appearance-based 3D Gaze Estimation	[[paper]](https://arxiv.org/abs/2201.07927)		
* 2021		High-Accuracy Gaze Estimation for Interpolation-Based Eye-Tracking Methods	[[paper]](https://www.mdpi.com/2411-5150/5/3/41)	
* 2021		Real-Time Precise Human-Computer Interaction System Based on Gaze Estimation and Tracking	[[paper]](https://www.hindawi.com/journals/wcmc/2021/8213946/)
* 2021		Effect Of Personalized Calibration On Gaze Estimation Using Deep-Learning	 [[paper]](https://arxiv.org/abs/2109.12801)
* 2021		Weakly-Supervised Physically Unconstrained Gaze Estimation	[[paper]](https://arxiv.org/pdf/2105.09803.pdf),	[[code]](https://github.com/NVlabs/weakly-supervised-gaze)
* 2021		Gaze Estimation with an Ensemble of Four Architectures	[[paper]](https://arxiv.org/abs/2107.01980)
* 2020		Unsupervised Representation Learning for Gaze Estimation	[[paper]](https://openaccess.thecvf.com/content_CVPR_2020/html/Yu_Unsupervised_Representation_Learning_for_Gaze_Estimation_CVPR_2020_paper.html)
* 2021	HybridGazeNet	HybridGazeNet: Geometric model guided Convolutional Neural Networks for gaze estimation	[[paper]](https://arxiv.org/abs/2111.11691)		
* 2018	[ELG]	Learning to Find Eye Region Landmarks for Remote Gaze Estimation in Unconstrained Settings	[[paper]](https://arxiv.org/abs/1805.04771), 	[[code]](https://github.com/swook/GazeML),	[[project]](https://ait.ethz.ch/projects/2018/landmarks-gaze/)
* 2018	[DPG]	Deep Pictorial Gaze Estimation	[[paper]](https://openaccess.thecvf.com/content_ECCV_2018/papers/Seonwook_Park_Deep_Pictorial_Gaze_ECCV_2018_paper.pdf),	[[code]](https://github.com/swook/GazeML),	[[project]](https://ait.ethz.ch/projects/2018/pictorial-gaze/)
* 2022	[MTGLS]	MTGLS: Multi-Task Gaze Estimation with Limited Supervision	[[paper]](https://openaccess.thecvf.com/content/WACV2022/html/Ghosh_MTGLS_Multi-Task_Gaze_Estimation_With_Limited_Supervision_WACV_2022_paper.html)		
* 2021	The Story in Your Eyes: An Individual-difference-aware Model for Cross-person Gaze Estimation	[[paper]](https://arxiv.org/abs/2106.14183),	[[code]](https://github.com/bjj9/EVE_SCPT)	
* 2021	[Puregaze]	Puregaze: Purifying gaze feature for generalizable gaze estimation	[[paper]](https://arxiv.org/abs/2103.13173),	[[code]](https://github.com/yihuacheng/puregaze)	

## Video-based methods

* 2019		Neuro-inspired eye tracking with eye movement dynamics	[[paper]](https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Neuro-Inspired_Eye_Tracking_With_Eye_Movement_Dynamics_CVPR_2019_paper.html)
* 2019		Realtime and accurate 3d eye gaze capture with dcnn-based iris and pupil segmentation	[[paper]](https://ieeexplore.ieee.org/abstract/document/8818661)
* 2019		Learning a 3d gaze estimator with improved itracker combined with bidirectional lstm  [[paper]](https://ieeexplore.ieee.org/abstract/document/8784770)				
* 2018		Recurrent cnn for 3d gaze estimation using appearance and shape cues  [[paper]](Recurrent cnn for 3d gaze estimation using appearance and shape cues)		
* 2019	[Gaze360]	Gaze360: Physically unconstrained gaze estimation in the wild	[[paper]](http://gaze360.csail.mit.edu/iccv2019_gaze360.pdf),	[[code]](https://github.com/Erkil1452/gaze360),	[[code2]](https://github.com/erkil1452/gaze360/tree/master/code),	[[project]](http://gaze360.csail.mit.edu/)
* 2020		Towards end-to-end video-based eye-tracking	[[paper]](https://arxiv.org/abs/2007.13120),	[[code]](https://github.com/swook/EVE)		
* 2022	[Puregaze]	Puregaze: Purifying gaze feature for generalizable gaze estimation	[[paper]](https://ojs.aaai.org/index.php/AAAI/article/view/19921),	[[code]](https://github.com/yihuacheng/PureGaze)	
* 2022	[HAZE-Net]	HAZE-Net: High-Frequency Attentive Super-Resolved Gaze Estimation in Low-Resolution Face Images	[[paper]](https://arxiv.org/abs/2209.10167),	[[code]](https://github.com/dbseorms16/haze_net)		
* 2022	[LatentGaze]	LatentGaze: Cross-Domain Gaze Estimation through Gaze-Aware Analytic Latent Code Manipulation	[[paper]](https://arxiv.org/abs/2209.10171),	[[code]](https://github.com/leeisack/latentgaze)		



